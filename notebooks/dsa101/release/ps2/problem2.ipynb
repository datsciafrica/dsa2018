{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSA 2018 Nyeri Preparatory Notebook\n",
    "\n",
    "Billy Okal\n",
    "\n",
    "In preparation for DSA 2018 Nyeri, we would like potential participants to complete a number of exercises in probability, machine learning and programming to ensure that they have the necessary prerequisite knowledge to attend the summer school. You will be required to submit notebooks with solutions to these exercises during the application process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will practise basic preparation techniques as concerns storage of data and models. This is a crucial process present in every data science project. As the project evolves, data may be manipulated and different model versions produced. These need to be tracked so as to maintain reproducibility, a crucial element of data science.\n",
    "\n",
    "There are many options for data and model storage in Python. In this exercise, we focus on elementary techniques requiring no more that the standard library. These ought to be applicable to even the smallest data science projects such as homeworks or course projects.\n",
    "\n",
    "This exercise is split into two parts, which should be completed in order. These mimic a typical workflow across a project's lifetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load some common libraries used here\n",
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part I: Data Preparation and Exploration\n",
    "\n",
    "In this part, we will load a dataset provided with this exercise, prepare it by converting to the right types and finally plot it to explore the data.\n",
    "\n",
    "The dataset is stored in a CSV file with the following columns;\n",
    "[feature_1,feature_2,label] \n",
    "The values in each line are separated by a comma (',')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the libraries above write a function to read the dataset.\n",
    "\n",
    "The filename specified below. The final dataset should be a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ORIGINAL_NAME = 'dataset_original.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "71f724bb4f4bd1d773f787fb6081e618",
     "grade": false,
     "grade_id": "load-implementation",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\" Load dataset from a CSV file.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    filename : str\n",
    "        The filename of the CSV.\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    data : array-like\n",
    "        Numpy array of the loaded data.\n",
    "        \n",
    "    Note\n",
    "    -----\n",
    "    Hints\n",
    "    1) Pay attention to the header (column names) when creating the array.\n",
    "    2) Pay attention to types read in (strings vs floats)\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_data(ORIGINAL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "954d0ea48786fc08b0fefb597d59136f",
     "grade": true,
     "grade_id": "load-test",
     "locked": true,
     "points": 8,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Check your implementation against these basic tests\n",
    "assert len(data) == 1000\n",
    "assert data.shape == (1000, 3)\n",
    "### BEGIN HIDDEN_TESTS\n",
    "assert np.unique(data[:, 2]).tolist() == [0, 1]\n",
    "### END HIDDEN_TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we explore the data by plotting it. \n",
    "\n",
    "Please use the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_dataset(data):\n",
    "    \"\"\" Plot a simple dataset \"\"\"\n",
    "    plt.scatter(data[:, 0], data[:, 1], marker='o', c=data[:, 2], s=25, edgecolor='k')\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "2bd81f2c12f049ae2a0129b21d8a28e9",
     "grade": true,
     "grade_id": "run-plot",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Enter the code to call the plot function above.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part II Post-processing Data\n",
    "\n",
    "In this part, we will modify the dataset. We make the assumption that there is some noise in the data define by the following rules:\n",
    "* Feature 1 should have values in the range $(-2, 2]$\n",
    "* Feature 2 should have values in the range $[-3, 1.5)$\n",
    "\n",
    "In practise, such rules are derived from domain knowledge from the area of interest. We will now filter the data and remove the 'noisy' samples (any sample which does not fall within ranges specified above). We also save the resulting dataset for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the data\n",
    "\n",
    "Implement a filter that uses the rules above to create a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0cf42d6f5df7a0e67df60cefb64c98ca",
     "grade": false,
     "grade_id": "filter-data",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def filter_data(data):\n",
    "    \"\"\" Filter dataset by removing samples which do not match the rules \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Dataset\n",
    "    Returns\n",
    "    -------\n",
    "    new_data : array-like\n",
    "        New dataset\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Execute the filter call\n",
    "new_data = filter_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "913ff2cc64e9e8d71165653c559520ac",
     "grade": true,
     "grade_id": "filter-data-correct",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test your implementation against the following.\n",
    "assert new_data.shape[0] == 804\n",
    "### BEGIN HIDDEN_TESTS\n",
    "assert (new_data[:, 0] > 2).all() == False\n",
    "assert (new_data[:, 0] < -2).all() == False\n",
    "assert (new_data[:, 1] < -3).all() == False\n",
    "assert (new_data[:, 1] > 1.5).all() == False\n",
    "### END HIDDEN_TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a function to save the new dataset into a CSV file, with the specified name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEW_FILE_NAME = 'dataset_clipped.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e72842fb70d95b3dfe81f0cafc775605",
     "grade": true,
     "grade_id": "cell-795ee4d62546b087",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the function to save the dataset\n",
    "save_dataset(new_data, NEW_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done! Hurray. Let us summarized what we have accomplished.\n",
    "\n",
    "- Reading data from CSV files\n",
    "    - Preparing the data by converting to appropriate types, removing headers\n",
    "- Exploration by visualizing the data\n",
    "- Post processing the data by removing samples that do not match a specified criteria.\n",
    "- Saving the new dataset as a CSV file. \n",
    "\n",
    "We are now ready to take the new dataset and start doing further analysis and/or model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
